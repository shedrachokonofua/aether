version: "3"

# Minimal Taskfile for Nix workflow
# Most tools are just available: tofu, ansible, sops, aws, step, bao
# This file only contains multi-step workflows and playbook shortcuts

vars:
  CACHE_DIR: ${HOME}/.aether-toolbox

env:
  ANSIBLE_CONFIG: ./ansible/ansible.cfg
  LC_ALL: C.UTF-8
  LANG: C.UTF-8
  AWS_REGION: us-east-1

tasks:
  # ===========================================================================
  # Auth (multi-step flows worth wrapping)
  # ===========================================================================
  login:
    desc: Unified SSO login (AWS + OpenBao + SSH cert)
    cmds:
      - mkdir -p {{.CACHE_DIR}}/bao {{.CACHE_DIR}}/step
      - AETHER_CACHE_DIR={{.CACHE_DIR}} ./scripts/login.sh {{.CLI_ARGS}}

  login:status:
    desc: Check auth status
    cmds:
      - AETHER_CACHE_DIR={{.CACHE_DIR}} ./scripts/login.sh --status

  # ===========================================================================
  # Tofu (only compound operations)
  # ===========================================================================
  tofu:init:
    desc: Init with backend config
    cmds:
      - sh ./scripts/create-tofu-state-config.sh
      - tofu -chdir=tofu init -backend-config=../config/tofu-state.config -upgrade -reconfigure

  tofu:apply:
    desc: Apply + write outputs + export k8s auth
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        tofu -chdir=tofu apply {{.CLI_ARGS}}
      - tofu -chdir=tofu output -json > ./secrets/tf-outputs.json
      - task: k8s:auth

  tofu:plan:
    desc: Plan changes
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        tofu -chdir=tofu plan {{.CLI_ARGS}}

  tofu:refresh:
    desc: Refresh + write outputs
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        tofu -chdir=tofu refresh {{.CLI_ARGS}}
      - tofu -chdir=tofu output -json > ./secrets/tf-outputs.json

  tofu:unlock:
    desc: Unlock state
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        tofu -chdir=tofu force-unlock {{.CLI_ARGS}}

  k8s:auth:
    desc: Export kubeconfig + talosconfig for cluster access
    cmds:
      - |
        mkdir -p ~/.kube ~/.talos
        if tofu -chdir=tofu output -raw talos_kubeconfig > ~/.kube/config 2>/dev/null && \
           tofu -chdir=tofu output -raw talos_client_configuration > ~/.talos/config 2>/dev/null; then
          echo "✅ Exported ~/.kube/config (kubectl) and ~/.talos/config (talosctl)"
        else
          echo "⏭️  No k8s cluster in state, skipping auth export"
        fi

  # ===========================================================================
  # Secrets (only needs Bao env vars - AWS uses ~/.aws/credentials, age uses .sops.yaml)
  # ===========================================================================
  sv:
    desc: View secrets
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        sops -d ./secrets/secrets.yml

  se:
    desc: Edit secrets
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        sops ./secrets/secrets.yml

  sg:
    desc: "Get secret (usage: task sg -- .path.to.key)"
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        sops -d ./secrets/secrets.yml | yq '{{.CLI_ARGS}}'

  sl:
    desc: List secret keys
    cmds:
      - |
        # [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        sops -d ./secrets/secrets.yml | yq '.. | path | select(length > 0) | "." + join(".")'

  sops:rotate:
    desc: Rotate all secrets with current keys
    cmds:
      - |
        [ -f "{{.CACHE_DIR}}/bao/token" ] && export VAULT_ADDR=https://bao.home.shdr.ch VAULT_TOKEN=$(cat {{.CACHE_DIR}}/bao/token)
        find secrets -name '*.yml' -o -name '*.yaml' | xargs -I{} sops updatekeys --yes {}

  # ===========================================================================
  # Ansible Galaxy (worth automating)
  # ===========================================================================
  galaxy:
    desc: Install Ansible dependencies
    dir: ./ansible
    cmds:
      - ansible-galaxy collection install -r requirements.yml
      - ansible-galaxy role install -r requirements.yml

  # ===========================================================================
  # NixOS Base Images
  # ===========================================================================
  nix:build-vm-image:
    desc: Build NixOS VM base image (qcow2 for Proxmox + Terraform)
    vars:
      STEP_CA_IP:
        sh: yq '.step_ca.ip' config/vm.yml
    cmds:
      - |
        echo "Fetching SSH CA public key from step-ca..."
        SSH_CA_PUBKEY=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@{{.STEP_CA_IP}} cat /etc/step-ca/certs/ssh_user_ca_key.pub)
        echo "Building VM base image (qcow2)..."
        rm -rf .nix-vm-image
        SSH_CA_PUBKEY="$SSH_CA_PUBKEY" nix build .#vm-base-image --impure -o .nix-vm-image
        echo "✅ Image built: $(ls .nix-vm-image/*.qcow2)"

  nix:build-lxc-image:
    desc: Build NixOS LXC base image (tar.xz for Proxmox)
    vars:
      STEP_CA_IP:
        sh: yq '.step_ca.ip' config/vm.yml
    cmds:
      - |
        echo "Fetching SSH CA public key from step-ca..."
        SSH_CA_PUBKEY=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@{{.STEP_CA_IP}} cat /etc/step-ca/certs/ssh_user_ca_key.pub)
        echo "Building LXC base image..."
        rm -rf .nix-lxc-image
        SSH_CA_PUBKEY="$SSH_CA_PUBKEY" nix build .#lxc-base-image --impure -o .nix-lxc-image
        echo "✅ Image built: $(ls .nix-lxc-image/tarball/*.tar.xz)"

  nix:upload-vm-image:
    desc: Upload VM base image to cephfs (for Terraform)
    deps: [nix:build-vm-image]
    vars:
      SMITH_IP: 192.168.2.204
    cmds:
      - |
        echo "Uploading VM image to cephfs..."
        ssh root@{{.SMITH_IP}} "mkdir -p /mnt/pve/cephfs/template/iso"
        rsync -avP .nix-vm-image/*.qcow2 root@{{.SMITH_IP}}:/mnt/pve/cephfs/template/iso/nixos-base-vm.qcow2.img
        echo "✅ Uploaded to cephfs:iso/nixos-base-vm.qcow2.img"
        echo ""
        echo "Reference in Terraform:"
        echo '  file_id = "cephfs:iso/nixos-base-vm.qcow2.img"'

  nix:upload-lxc-image:
    desc: Upload LXC base image to cephfs (shared across all nodes)
    deps: [nix:build-lxc-image]
    vars:
      SMITH_IP: 192.168.2.204
    cmds:
      - |
        echo "Uploading LXC image to cephfs..."
        ssh root@{{.SMITH_IP}} "mkdir -p /mnt/pve/cephfs/template/cache"
        rsync -avP .nix-lxc-image/tarball/*.tar.xz root@{{.SMITH_IP}}:/mnt/pve/cephfs/template/cache/nixos-base-lxc.tar.xz
        echo "✅ Uploaded to cephfs:vztmpl/nixos-base-lxc.tar.xz"

  # ===========================================================================
  # Playbooks
  # ===========================================================================
  provision:infra:
    cmds: [task: tofu:init, task: tofu:apply]

  ansible:playbook:
    cmds:
      - ansible-playbook ansible/playbooks/{{.CLI_ARGS}}
  provision:router:
    cmds:
      - ansible-playbook ansible/playbooks/home_router/site.yml
  configure:router:
    cmds: [ansible-playbook ansible/playbooks/home_router/configure_router.yml]
  provision:nfs:
    cmds: [ansible-playbook ansible/playbooks/network_file_server/site.yml]
  configure:gateway:
    cmds: [ansible-playbook ansible/playbooks/home_gateway_stack/site.yml]
  configure:caddy:
    cmds: [ansible-playbook ansible/playbooks/home_gateway_stack/caddy/site.yml]
  configure:monitoring:
    cmds: [ansible-playbook ansible/playbooks/monitoring_stack/site.yml]
  configure:dokploy:
    cmds: [ansible-playbook ansible/playbooks/dokploy/site.yml]
  configure:gitlab:
    cmds: [ansible-playbook ansible/playbooks/gitlab/site.yml]
  configure:backup:
    cmds: [ansible-playbook ansible/playbooks/backup_stack/site.yml]
  configure:iot:
    cmds: [ansible-playbook ansible/playbooks/iot_management_stack/site.yml]
  configure:vm-agents:
    cmds: [ansible-playbook ansible/playbooks/setup_vm_monitoring_agents.yml]
  configure:host-agents:
    cmds: [ansible-playbook ansible/playbooks/setup_host_monitoring_agents.yml]
  configure:cockpit-agents:
    cmds: [ansible-playbook ansible/playbooks/setup_cockpit_agents.yml]
  configure:dev-workstation:
    cmds: [ansible-playbook ansible/playbooks/dev_workstation/site.yml]
  configure:cockpit:
    cmds: [ansible-playbook ansible/playbooks/cockpit/site.yml]
  configure:gpu-workstation:
    cmds: [ansible-playbook ansible/playbooks/gpu_workstation/site.yml]
  configure:ai-tools:
    cmds: [ansible-playbook ansible/playbooks/ai_tool_stack/site.yml]
  configure:litellm:
    cmds: [ansible-playbook ansible/playbooks/ai_tool_stack/litellm/site.yml]
  configure:firecrawl:
    cmds: [ansible-playbook ansible/playbooks/ai_tool_stack/firecrawl.yml]
  configure:media-stack:
    cmds: [ansible-playbook ansible/playbooks/media_stack/site.yml]
  configure:tuliprox:
    cmds: [ansible-playbook ansible/playbooks/media_stack/tuliprox/site.yml]
  configure:messaging-stack:
    cmds: [ansible-playbook ansible/playbooks/messaging_stack/site.yml]
  configure:ups-management-stack:
    cmds: [ansible-playbook ansible/playbooks/ups_management_stack/site.yml]
  configure:dokku:
    cmds: [ansible-playbook ansible/playbooks/dokku/site.yml]
  configure:smallweb:
    cmds: [ansible-playbook ansible/playbooks/smallweb/site.yml]
  provision:keycloak:
    cmds: [ansible-playbook ansible/playbooks/keycloak/site.yml]
  configure:keycloak:
    cmds: [ansible-playbook ansible/playbooks/keycloak/deploy_keycloak.yml]
  configure:public-gateway:
    cmds: [ansible-playbook ansible/playbooks/public_gateway_stack/site.yml]
  provision:game-server:
    cmds: [ansible-playbook ansible/playbooks/game_server/site.yml]
  provision:step-ca:
    cmds: [ansible-playbook ansible/playbooks/step_ca/site.yml]
  provision:step-ca-trust:
    cmds: [ansible-playbook ansible/playbooks/step_ca/provision_aws_trust.yml]
  configure:step-ca:
    cmds: [ansible-playbook ansible/playbooks/step_ca/deploy_step_ca.yml]
  provision:adguard:
    desc: Provision AdGuard LXC from base image
    cmds: [ansible-playbook ansible/playbooks/adguard/site.yml]
  # ===========================================================================
  # NixOS Deploy Helper (internal)
  # ===========================================================================
  _nixos-deploy:
    internal: true
    desc: Internal helper for NixOS deployments
    vars:
      STEP_CA_IP:
        sh: yq '.step_ca.ip' config/vm.yml
    cmds:
      - |
        SSH_CA_PUBKEY=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null root@{{.STEP_CA_IP}} cat /etc/step-ca/certs/ssh_user_ca_key.pub)
        SSH_CA_PUBKEY="$SSH_CA_PUBKEY" nix run nixpkgs#nixos-rebuild -- switch --flake .#{{.FLAKE_TARGET}} --target-host root@{{.TARGET_IP}} --impure

  configure:adguard:
    desc: Deploy NixOS configuration to AdGuard LXC
    vars:
      TARGET_IP:
        sh: yq '.adguard.ip' config/vm.yml
    cmds:
      - task: _nixos-deploy
        vars:
          TARGET_IP: "{{.TARGET_IP}}"
          FLAKE_TARGET: adguard
  deploy:adguard:
    desc: Full deploy - provision LXC + configure NixOS
    cmds:
      - task: provision:adguard
      - task: configure:adguard
  provision:ids-mirror-bridge:
    desc: Create isolated bridge for IDS mirror traffic (one-time)
    cmds:
      [ansible-playbook ansible/playbooks/home_router/create_mirror_bridge.yml]
  configure:ids-stack:
    desc: Deploy NixOS configuration to IDS Stack VM
    vars:
      TARGET_IP:
        sh: yq '.ids_stack.ip' config/vm.yml
    cmds:
      - task: _nixos-deploy
        vars:
          TARGET_IP: "{{.TARGET_IP}}"
          FLAKE_TARGET: ids-stack
  deploy:ids-stack:
    desc: Full deploy - provision VM + configure NixOS
    cmds:
      - task: provision:ids-mirror-bridge
      - task: tofu:apply
        vars: { CLI_ARGS: "-target=proxmox_virtual_environment_vm.ids_stack" }
      - task: configure:ids-stack
  configure:blockchain-stack:
    desc: Deploy NixOS configuration to Blockchain Stack VM
    vars:
      TARGET_IP:
        sh: yq '.blockchain_stack.ip' config/vm.yml
    cmds:
      - task: _nixos-deploy
        vars:
          TARGET_IP: "{{.TARGET_IP}}"
          FLAKE_TARGET: blockchain-stack
  deploy:blockchain-stack:
    desc: Full deploy - provision VM + configure NixOS
    cmds:
      - task: tofu:apply
        vars:
          {
            CLI_ARGS: "-target=proxmox_virtual_environment_vm.blockchain_stack",
          }
      - task: configure:blockchain-stack
  configure:openclaw:
    desc: Deploy NixOS configuration to OpenClaw VM
    vars:
      TARGET_IP:
        sh: yq '.openclaw.ip' config/vm.yml
    cmds:
      - task: _nixos-deploy
        vars:
          TARGET_IP: "{{.TARGET_IP}}"
          FLAKE_TARGET: openclaw
  deploy:openclaw:
    desc: Full deploy - provision VM + configure NixOS
    cmds:
      - task: tofu:apply
        vars:
          {
            CLI_ARGS: "-target=proxmox_virtual_environment_vm.openclaw",
          }
      - task: configure:openclaw
  provision:openbao:
    cmds: [ansible-playbook ansible/playbooks/openbao/site.yml]
  provision:openbao-kms:
    cmds: [ansible-playbook ansible/playbooks/openbao/provision_aws_kms.yml]
  configure:openbao:
    cmds: [ansible-playbook ansible/playbooks/openbao/deploy_openbao.yml]
  configure:ssh-ca:
    cmds: [ansible-playbook ansible/playbooks/configure_ssh_ca_trust.yml]
  configure:ssh-keys:
    cmds: [ansible-playbook ansible/playbooks/update_authorized_keys.yml]
  baseline:machines:
    cmds: [ansible-playbook ansible/playbooks/baseline_machines.yml]
  baseline:vms:
    cmds: [ansible-playbook ansible/playbooks/baseline_vms.yml]
  upgrade:pve:
    desc: Upgrade Proxmox VE 8 to 9 (serial, one node at a time)
    cmds:
      - ansible-playbook ansible/playbooks/upgrade_pve_8_to_9.yml {{.CLI_ARGS}}

  configure:all:
    cmds:
      - task: configure:gateway
      - task: configure:monitoring
      - task: configure:dokploy
      - task: configure:gitlab
      - task: configure:backup
